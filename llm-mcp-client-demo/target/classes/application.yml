server.port: 10101

spring:
  application:
    name: llm-mcp-client-demo

  ai:
    chat:
      client:
        observations:
          log-prompt: true
      observations:
        log-prompt: true
        log-completion: true
        include-error-logging: true

    anthropic:
      api-key: ${ANTHROPIC_API_KEY}
      chat:
        options:
          model: claude-sonnet-4-20250514
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: o4-mini-2025-04-16
    vertex.ai.gemini:
      chat:
        options:
          model: gemini-2.5-flash-preview-05-20
      project-id: ${GOOGLE_PROJECT_ID}
      location: ${GOOGLE_ZONE}
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.2:latest

    mcp:
      client:
        enabled: true
        name: llm-mcp-client-demo
        version: 1.0.0
        initialized: true
        request-timeout: 20s
        type: sync
        root-change-notification: true
        toolcallback.enabled: true
        sse:
          connections:
            server1:
              url: http://localhost:8080
              sse-endpoint: /api/v1/sse

  security:
    oauth2:
      client:
        registration:
          my-client1:
            provider: auth-server
            client-id: mcp-client
            client-secret: mcp-secret
            authorization-grant-type: client_credentials
            scope:
              - mcp
        provider:
          auth-server:
            token-uri: http://localhost:9000/oauth2/token

  autoconfigure:
    exclude:
      - org.springframework.ai.mcp.client.autoconfigure.SseWebFluxTransportAutoConfiguration


logging:
  level:
    io.modelcontextprotocol: TRACE
    org.springframework.ai.mcp: TRACE

management:
  tracing:
    sampling:
      probability: 1.0
    enabled: true
  endpoints:
    web:
      exposure:
        # Open up all Spring Boot Actuator endpoints for the demo, don't do this in production!
        include: "*"

  prometheus:
    metrics:
      export:
        enabled: true
        step: 5s

  endpoint:
    health:
      show-details: always

  metrics:
    tags:
      application: ${spring.application.name}
      env: local
    distribution:
      percentiles-histogram:
        all: true
    enable:
      all: true

  otlp:
    tracing:
      endpoint: "http://localhost:4317"
      transport: grpc
